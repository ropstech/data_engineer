# data_engineer
Data Engineer specific learnings

## Day 1

1. **Key Concepts**
    - Review what a data engineer does and the key components of a data pipeline.
        
        -

    - Understand ETL vs. ELT and event-driven architectures.
    - Learn about **batch vs. stream processing**.
        - Technologies: Apache Beam (for stream processing) and Airflow (for orchestration).
2. **Resources**
    - Read about **big data architectures** in cloud environments (search for Google Cloud documentation).
    - Watch a YouTube crash course on data engineering (e.g., "Data Engineering Full Course" by Simplilearn or DataCamp).
3. **Hands-On**
    - Write a basic Python script to simulate an ETL pipeline:
        - Extract a dataset (e.g., CSV).
        - Transform it (clean, filter, add new columns).
        - Load it into another format or database (SQLite or Google BigQuery).
4. **Optional**
    - Explore SQL and NoSQL basics:
        - SQL: Basic queries, joins, and aggregations.
        - NoSQL: Look into MongoDB or Firebase.